{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pymongo\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# !pip install nltk\n",
    "import nltk\n",
    "# nltk.download()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('entries.csv'):\n",
    "    uri = \"mongodb+srv://\" + urllib.parse.quote(\"user\") + \":\" + urllib.parse.quote(\"Pizza.network1\") + \"@dentries-nsb6p.mongodb.net/test?retryWrites=true&w=majority\"\n",
    "    client = pymongo.MongoClient(uri)\n",
    "    db = client.diary_entries_db\n",
    "    db.list_collection_names()\n",
    "    collection = db['diary_entries']\n",
    "    df = pd.DataFrame(list(collection.find()))\n",
    "    df.to_csv('entries.csv')\n",
    "else:\n",
    "    df = pd.read_csv('entries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['_id', 'date', 'startTime', 'endTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str.lower().str.replace(r'[.?,!]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['goodMood'] = df['goodMood'].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>goodMood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11-9-2017</td>\n",
       "      <td>hello how should i start umm well i am making ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11-11-2017</td>\n",
       "      <td>ok so new plan i just sleep after i take my sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11-13-2017</td>\n",
       "      <td>well a lot has happened okay sorry for not wri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11-14-2017</td>\n",
       "      <td>damn it i overslept again i hate myself right ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11-15-2017</td>\n",
       "      <td>so i went on a run today yodai was there too t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title                                            content  goodMood\n",
       "0   11-9-2017  hello how should i start umm well i am making ...         1\n",
       "1  11-11-2017  ok so new plan i just sleep after i take my sh...         1\n",
       "2  11-13-2017  well a lot has happened okay sorry for not wri...         0\n",
       "3  11-14-2017  damn it i overslept again i hate myself right ...         0\n",
       "4  11-15-2017  so i went on a run today yodai was there too t...         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 77)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['goodMood'] == 0].shape[0], df.loc[df['goodMood'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>i</td>\n",
       "      <td>3514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>to</td>\n",
       "      <td>1674</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>the</td>\n",
       "      <td>1183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is</td>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count  length\n",
       "i     3514       1\n",
       "to    1674       2\n",
       "the   1183       3\n",
       "a      888       1\n",
       "is     850       2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten(ll):\n",
    "    s = []\n",
    "    for l in ll:\n",
    "        s.extend(l)\n",
    "    return s\n",
    "    \n",
    "unique_words = pd.DataFrame(pd.Series(flatten(df['content'].str.split(' '))).value_counts(), columns=['count'])\n",
    "unique_words['length'] = unique_words.index.str.len()\n",
    "number_of_words = np.sum(unique_words['count'])\n",
    "unique_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(unique_words['count'][:10] / number_of_words);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(unique_words['count'][10:20] / number_of_words);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(unique_words['count'][20:30] / number_of_words);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_pre_rec(y, y_hat):\n",
    "    tp = np.sum((y == y_hat) & (y == 1))\n",
    "    tn = np.sum((y == y_hat) & (y == 0))\n",
    "    fp = np.sum((y != y_hat) & (y == 0))\n",
    "    fn = np.sum((y != y_hat) & (y == 1))\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(term, corpus):\n",
    "    counts = corpus.str.count(re.escape(term))\n",
    "    return counts / corpus.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(term, corpus):\n",
    "    return np.log(corpus.shape[0]) / np.sum(corpus.str.contains(term, regex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(term, corpus):\n",
    "    return tf(term, corpus) * idf(term, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "vader_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>goodMood</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11-9-2017</td>\n",
       "      <td>hello how should i start umm well i am making ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11-11-2017</td>\n",
       "      <td>ok so new plan i just sleep after i take my sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.9230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11-13-2017</td>\n",
       "      <td>well a lot has happened okay sorry for not wri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.9386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11-14-2017</td>\n",
       "      <td>damn it i overslept again i hate myself right ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.4218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11-15-2017</td>\n",
       "      <td>so i went on a run today yodai was there too t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.7692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title                                            content  goodMood  \\\n",
       "0   11-9-2017  hello how should i start umm well i am making ...         1   \n",
       "1  11-11-2017  ok so new plan i just sleep after i take my sh...         1   \n",
       "2  11-13-2017  well a lot has happened okay sorry for not wri...         0   \n",
       "3  11-14-2017  damn it i overslept again i hate myself right ...         0   \n",
       "4  11-15-2017  so i went on a run today yodai was there too t...         1   \n",
       "\n",
       "     neg    neu    pos  compound  \n",
       "0  0.050  0.872  0.078    0.7269  \n",
       "1  0.069  0.787  0.144    0.9230  \n",
       "2  0.140  0.758  0.102   -0.9386  \n",
       "3  0.095  0.807  0.099    0.4218  \n",
       "4  0.107  0.835  0.058   -0.7692  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "for i in range(vader_df.shape[0]):\n",
    "    result = vader_analyzer.polarity_scores(vader_df.loc[i, 'content'])\n",
    "    vader_df.loc[i, 'neg'] = result['neg']\n",
    "    vader_df.loc[i, 'neu'] = result['neu']\n",
    "    vader_df.loc[i, 'pos'] = result['pos']\n",
    "    vader_df.loc[i, 'compound'] = result['compound']\n",
    "\n",
    "vader_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.576271186440678, 0.5081967213114754, 0.8051948051948052)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = vader_df['goodMood']\n",
    "y_hat = (vader_df['pos'] > vader_df['neg']).astype(int)\n",
    "acc_pre_rec(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data = {word: tfidf(word, tfidf_df['content']) for word in unique_words.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data_df = pd.DataFrame(tfidf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>to</th>\n",
       "      <th>the</th>\n",
       "      <th>a</th>\n",
       "      <th>is</th>\n",
       "      <th>and</th>\n",
       "      <th>it</th>\n",
       "      <th>that</th>\n",
       "      <th>my</th>\n",
       "      <th>have</th>\n",
       "      <th>...</th>\n",
       "      <th>dizzy</th>\n",
       "      <th>tabs</th>\n",
       "      <th>supports</th>\n",
       "      <th>80%</th>\n",
       "      <th>coke</th>\n",
       "      <th>haas</th>\n",
       "      <th>demo</th>\n",
       "      <th>eecs126</th>\n",
       "      <th>colors</th>\n",
       "      <th>careful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.014374</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.019496</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.012061</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3498 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          i        to       the         a        is       and        it  \\\n",
       "0  0.011731  0.001652  0.001521  0.014374  0.001345  0.001057  0.001014   \n",
       "1  0.009913  0.001487  0.000845  0.011565  0.001008  0.000705  0.001014   \n",
       "2  0.018670  0.003304  0.002028  0.019496  0.002521  0.001233  0.000845   \n",
       "3  0.012061  0.001652  0.001859  0.011731  0.001513  0.000705  0.001183   \n",
       "4  0.007435  0.000991  0.001183  0.006774  0.001008  0.000000  0.000507   \n",
       "\n",
       "       that        my      have  ...  dizzy      tabs  supports  80%  coke  \\\n",
       "0  0.000183  0.000705  0.000187  ...    0.0  0.000000       0.0  0.0   0.0   \n",
       "1  0.000731  0.000705  0.000000  ...    0.0  0.000000       0.0  0.0   0.0   \n",
       "2  0.001462  0.000352  0.000562  ...    0.0  0.000000       0.0  0.0   0.0   \n",
       "3  0.000914  0.000529  0.000375  ...    0.0  0.029244       0.0  0.0   0.0   \n",
       "4  0.000548  0.000529  0.000187  ...    0.0  0.000000       0.0  0.0   0.0   \n",
       "\n",
       "   haas  demo  eecs126  colors  careful  \n",
       "0   0.0   0.0      0.0     0.0      0.0  \n",
       "1   0.0   0.0      0.0     0.0      0.0  \n",
       "2   0.0   0.0      0.0     0.0      0.0  \n",
       "3   0.0   0.0      0.0     0.0      0.0  \n",
       "4   0.0   0.0      0.0     0.0      0.0  \n",
       "\n",
       "[5 rows x 3498 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      0.182396\n",
       "a     0.012086\n",
       "i     0.011910\n",
       "s     0.008243\n",
       "h     0.007296\n",
       "r     0.006935\n",
       "m     0.004691\n",
       "g     0.003711\n",
       "th    0.003571\n",
       "c     0.003153\n",
       "dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tfidf_data_df, axis=0).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, y_train, y_test = train_test_split(tfidf_df['content'], tfidf_df['goodMood'], \n",
    "                                                    test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000webhost', '04', '10', '100']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(data_train)\n",
    "\n",
    "X_test = vectorizer.transform(data_test)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5833333333333334, 1.0, 0.11764705882352941)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_logistic_model = LogisticRegression(solver='lbfgs')\n",
    "tfidf_logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = tfidf_logistic_model.predict(X_test)\n",
    "acc_pre_rec(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shershah/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5555555555555556, 0.5555555555555556, 0.29411764705882354)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_rfc_model = RandomForestClassifier()\n",
    "tfidf_rfc_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = tfidf_rfc_model.predict(X_test)\n",
    "acc_pre_rec(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = list(stopwords.words('english'))\n",
    "\n",
    "bow_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_unique_words = unique_words.loc[~unique_words.index.isin(stopwords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>need</td>\n",
       "      <td>286</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>also</td>\n",
       "      <td>260</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>going</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>work</td>\n",
       "      <td>232</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>really</td>\n",
       "      <td>215</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  length\n",
       "need      286       4\n",
       "also      260       4\n",
       "going     250       5\n",
       "work      232       4\n",
       "really    215       6"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_unique_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, y_train, y_test = train_test_split(bow_df['content'], bow_df['goodMood'], \n",
    "                                                    test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame({word: data_train.str.count(re.escape(word)) for word in bow_unique_words.index})\n",
    "X_test = pd.DataFrame({word: data_test.str.count(re.escape(word)) for word in bow_unique_words.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shershah/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6111111111111112, 0.6153846153846154, 0.47058823529411764)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_logistic_model = LogisticRegression(solver='lbfgs')\n",
    "bow_logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = bow_logistic_model.predict(X_test)\n",
    "acc_pre_rec(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB()),])\n",
    "text_clf = text_clf.fit(data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5555555555555556, 1.0, 0.058823529411764705)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_pre_rec(y_test, text_clf.predict(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                ('clf-svm',\n",
       "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=42,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                          alpha=1e-3, random_state=42)),\n",
    "])\n",
    "\n",
    "text_clf_svm.fit(data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6388888888888888, 0.6111111111111112, 0.6470588235294118)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_pre_rec(y_test, text_clf_svm.predict(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19     hey so now i am adding titles to my diary entr...\n",
       "45     so i am currently working on data science stuf...\n",
       "139    i am back home i have lot to do finals were br...\n",
       "30     so i went to virginia the plane ride was long ...\n",
       "67     i am realy sleepy right now i don't know why i...\n",
       "16     sorry for not writing soon i have been busy an...\n",
       "119    well it is now official spring break i finishe...\n",
       "173    i got paid finally sure it is only a fraction ...\n",
       "109    my family execpt sama went off to pakistan yes...\n",
       "140    so i had my phone interview today with northru...\n",
       "24     it has been a while hasn't it i feel so tired ...\n",
       "161    classes start tomorrow i am not ready nor do i...\n",
       "41     so i am making chili i bought all the ingredie...\n",
       "118    sorry i have not written in a while i have not...\n",
       "15     sorry for not writing in a while i just got re...\n",
       "111    i am writting this from my bed the day was lon...\n",
       "113    so today was sarah's birthday she got a cake a...\n",
       "82     hey i really need to get better at making thes...\n",
       "9      okay i have a few things to explain one two da...\n",
       "114    so today stuff happened i showered i ate a nic...\n",
       "18     okay so i just finished watching episode twele...\n",
       "66     i am finished with finals man that was not har...\n",
       "60     sorry for not writting in a while a lot of thi...\n",
       "168    so i basically failed all of my midterms but i...\n",
       "170    so there is an extra credit assignment for cs6...\n",
       "150    a lot has happened the most important thing i ...\n",
       "117    so steven hawking died today i got some good w...\n",
       "65     hey so i am back home it is good to be back i ...\n",
       "90     okay so i have not been too good keeping this ...\n",
       "55     so my family is back from pakistan it is nice ...\n",
       "29     so a lot happened over the weekend my family c...\n",
       "127    i am really board and i do not want to do anyt...\n",
       "144                             nader is going to jordan\n",
       "31     hey sorry for the long period of no activity s...\n",
       "12     wow it is the last month of the year sorry for...\n",
       "42     so i tried to make cinnamon buns today they di...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_train = [list(nltk.bigrams(nltk.word_tokenize(s))) for s in bigram_df['content']]\n",
    "bigrams_train = [[a + ' ' + b for a, b in l] for l in bigrams_train]\n",
    "_bigrams_train = np.unique(np.array(bigrams_train))\n",
    "bigrams_train = []\n",
    "for bigrams in _bigrams_train:\n",
    "            bigrams_train.extend(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('so', 'the'),\n",
       " ('the', 'backend'),\n",
       " ('backend', 'is'),\n",
       " ('is', 'now'),\n",
       " ('now', 'connected'),\n",
       " ('connected', 'to'),\n",
       " ('to', 'mongodb'),\n",
       " ('mongodb', 'this'),\n",
       " ('this', 'means'),\n",
       " ('means', 'that'),\n",
       " ('that', 'there'),\n",
       " ('there', 'are'),\n",
       " ('are', 'no'),\n",
       " ('no', 'more'),\n",
       " ('more', 'files'),\n",
       " ('files', 'to'),\n",
       " ('to', 'worry'),\n",
       " ('worry', 'about'),\n",
       " ('about', 'everything'),\n",
       " ('everything', 'is'),\n",
       " ('is', 'stored'),\n",
       " ('stored', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'cloud'),\n",
       " ('cloud', 'it'),\n",
       " ('it', 'is'),\n",
       " ('is', 'also'),\n",
       " ('also', 'awesome'),\n",
       " ('awesome', 'because'),\n",
       " ('because', 'i'),\n",
       " ('i', 'now'),\n",
       " ('now', 'know'),\n",
       " ('know', 'the'),\n",
       " ('the', 'mean'),\n",
       " ('mean', 'stack'),\n",
       " ('stack', 'which'),\n",
       " ('which', 'is'),\n",
       " ('is', 'mongodb'),\n",
       " ('mongodb', 'expressjs'),\n",
       " ('expressjs', 'angularjs'),\n",
       " ('angularjs', 'and'),\n",
       " ('and', 'nodejs'),\n",
       " ('nodejs', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'going'),\n",
       " ('going', 'to'),\n",
       " ('to', 'put'),\n",
       " ('put', 'that'),\n",
       " ('that', 'on'),\n",
       " ('on', 'my'),\n",
       " ('my', 'resume'),\n",
       " ('resume', 'right'),\n",
       " ('right', 'away'),\n",
       " ('away', 'tommy'),\n",
       " ('tommy', 'is'),\n",
       " ('is', 'working'),\n",
       " ('working', 'for'),\n",
       " ('for', 'his'),\n",
       " ('his', 'company'),\n",
       " ('company', 'but'),\n",
       " ('but', 'he'),\n",
       " ('he', 'says'),\n",
       " ('says', 'there'),\n",
       " ('there', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'lot'),\n",
       " ('lot', 'of'),\n",
       " ('of', 'drama'),\n",
       " ('drama', 'i'),\n",
       " ('i', 'hope'),\n",
       " ('hope', 'he'),\n",
       " ('he', 'gets'),\n",
       " ('gets', 'though'),\n",
       " ('though', 'it'),\n",
       " ('it', 'fine'),\n",
       " ('fine', 'i'),\n",
       " ('i', 'have'),\n",
       " ('have', 'been'),\n",
       " ('been', 'studying'),\n",
       " ('studying', 'probability'),\n",
       " ('probability', 'to'),\n",
       " ('to', 'a'),\n",
       " ('a', 'little'),\n",
       " ('little', 'degree'),\n",
       " ('degree', 'of'),\n",
       " ('of', 'success'),\n",
       " ('success', 'i'),\n",
       " ('i', 'also'),\n",
       " ('also', 'need'),\n",
       " ('need', 'to'),\n",
       " ('to', 'work'),\n",
       " ('work', 'on'),\n",
       " ('on', 'askoski'),\n",
       " ('askoski', 'more'),\n",
       " ('more', 'summer'),\n",
       " ('summer', 'is'),\n",
       " ('is', 'coming'),\n",
       " ('coming', 'to'),\n",
       " ('to', 'a'),\n",
       " ('a', 'close'),\n",
       " ('close', 'and'),\n",
       " ('and', 'i'),\n",
       " ('i', 'hope'),\n",
       " ('hope', 'i'),\n",
       " ('i', 'spent'),\n",
       " ('spent', 'it'),\n",
       " ('it', 'well'),\n",
       " ('well', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'a'),\n",
       " ('a', 'bit'),\n",
       " ('bit', 'worried'),\n",
       " ('worried', 'about'),\n",
       " ('about', 'move-in'),\n",
       " ('move-in', 'since'),\n",
       " ('since', 'i'),\n",
       " ('i', 'still'),\n",
       " ('still', 'have'),\n",
       " ('have', 'not'),\n",
       " ('not', 'got'),\n",
       " ('got', 'my'),\n",
       " ('my', 'move-in'),\n",
       " ('move-in', 'time'),\n",
       " ('time', 'i'),\n",
       " ('i', 'should'),\n",
       " ('should', 'call'),\n",
       " ('call', 'the'),\n",
       " ('the', 'berk'),\n",
       " ('berk', 'office'),\n",
       " ('office', 'i'),\n",
       " ('i', 'also'),\n",
       " ('also', 'read'),\n",
       " ('read', 'reviews'),\n",
       " ('reviews', 'that'),\n",
       " ('that', 'said'),\n",
       " ('said', 'the'),\n",
       " ('the', 'berk'),\n",
       " ('berk', 'was'),\n",
       " ('was', 'not'),\n",
       " ('not', 'a'),\n",
       " ('a', 'great'),\n",
       " ('great', 'place'),\n",
       " ('place', 'to'),\n",
       " ('to', 'stay'),\n",
       " ('stay', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'worried'),\n",
       " ('worried', 'about'),\n",
       " ('about', 'that'),\n",
       " ('that', 'i'),\n",
       " ('i', 'should'),\n",
       " ('should', 'also'),\n",
       " ('also', 'talk'),\n",
       " ('talk', 'to'),\n",
       " ('to', 'my'),\n",
       " ('my', 'roommates'),\n",
       " ('roommates', 'and'),\n",
       " ('and', 'see'),\n",
       " ('see', 'what'),\n",
       " ('what', 'they'),\n",
       " ('they', 'think'),\n",
       " ('think', 'or'),\n",
       " ('or', 'know'),\n",
       " ('know', 'i'),\n",
       " ('i', 'hope'),\n",
       " ('hope', 'everything'),\n",
       " ('everything', 'goes'),\n",
       " ('goes', 'alright'),\n",
       " ('alright', 'i'),\n",
       " ('i', 'tried'),\n",
       " ('tried', 'to'),\n",
       " ('to', 'restart'),\n",
       " ('restart', 'my'),\n",
       " ('my', 'running'),\n",
       " ('running', 'my'),\n",
       " ('my', 'knee'),\n",
       " ('knee', 'still'),\n",
       " ('still', 'hurts'),\n",
       " ('hurts', 'mom'),\n",
       " ('mom', 'made'),\n",
       " ('made', 'an'),\n",
       " ('an', 'appointment'),\n",
       " ('appointment', 'with'),\n",
       " ('with', 'the'),\n",
       " ('the', 'doctor'),\n",
       " ('doctor', 'for'),\n",
       " ('for', 'this'),\n",
       " ('this', 'friday'),\n",
       " ('friday', 'i'),\n",
       " ('i', 'hope'),\n",
       " ('hope', 'it'),\n",
       " ('it', 'goes'),\n",
       " ('goes', 'well'),\n",
       " ('this', 'is'),\n",
       " ('is', 'it'),\n",
       " ('it', 'it'),\n",
       " ('it', 'is'),\n",
       " ('is', 'the'),\n",
       " ('the', 'end'),\n",
       " ('end', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'semester'),\n",
       " ('semester', 'well'),\n",
       " ('well', 'there'),\n",
       " ('there', 'are'),\n",
       " ('are', 'finals'),\n",
       " ('finals', 'but'),\n",
       " ('but', 'that'),\n",
       " ('that', 'is'),\n",
       " ('is', 'about'),\n",
       " ('about', 'it'),\n",
       " ('it', 'my'),\n",
       " ('my', 'history'),\n",
       " ('history', 'paper'),\n",
       " ('paper', 'is'),\n",
       " ('is', 'due'),\n",
       " ('due', 'tomorrow'),\n",
       " ('tomorrow', 'all'),\n",
       " ('all', 'i'),\n",
       " ('i', 'hvae'),\n",
       " ('hvae', 'left'),\n",
       " ('left', 'is'),\n",
       " ('is', 'to'),\n",
       " ('to', 'make'),\n",
       " ('make', 'some'),\n",
       " ('some', 'edits'),\n",
       " ('edits', 'i'),\n",
       " ('i', 'worked'),\n",
       " ('worked', 'on'),\n",
       " ('on', 'my'),\n",
       " ('my', 'wesite'),\n",
       " ('wesite', 'yesterday'),\n",
       " ('yesterday', 'well'),\n",
       " ('well', 'techically'),\n",
       " ('techically', 'it'),\n",
       " ('it', 'was'),\n",
       " ('was', 'today'),\n",
       " ('today', 'css'),\n",
       " ('css', 'can'),\n",
       " ('can', 'be'),\n",
       " ('be', 'frustrating'),\n",
       " ('frustrating', 'at'),\n",
       " ('at', 'times'),\n",
       " ('times', 'other'),\n",
       " ('other', 'than'),\n",
       " ('than', 'this'),\n",
       " ('this', 'not'),\n",
       " ('not', 'much'),\n",
       " ('much', 'is'),\n",
       " ('is', 'going'),\n",
       " ('going', 'on'),\n",
       " ('on', 'i'),\n",
       " ('i', 'submitted'),\n",
       " ('submitted', 'my'),\n",
       " ('my', 'scheme'),\n",
       " ('scheme', 'art'),\n",
       " ('art', 'two'),\n",
       " ('two', 'days'),\n",
       " ('days', 'ago'),\n",
       " ('ago', 'i'),\n",
       " ('i', 'have'),\n",
       " ('have', 'a'),\n",
       " ('a', 'bit'),\n",
       " ('bit', 'of'),\n",
       " ('of', 'time'),\n",
       " ('time', 'before'),\n",
       " ('before', 'class'),\n",
       " ('class', 'starts'),\n",
       " ('starts', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'going'),\n",
       " ('going', 'to'),\n",
       " ('to', 'take'),\n",
       " ('take', 'a'),\n",
       " ('a', 'shower'),\n",
       " ('shower', 'but'),\n",
       " ('but', 'i'),\n",
       " ('i', \"don't\"),\n",
       " (\"don't\", 'know'),\n",
       " ('know', 'what'),\n",
       " ('what', \"i'll\"),\n",
       " (\"i'll\", 'do'),\n",
       " ('do', 'after'),\n",
       " ('after', 'that'),\n",
       " ('that', 'i'),\n",
       " ('i', \"can't\"),\n",
       " (\"can't\", 'wait'),\n",
       " ('wait', 'for'),\n",
       " ('for', 'this'),\n",
       " ('this', 'all'),\n",
       " ('all', 'to'),\n",
       " ('to', 'be'),\n",
       " ('be', 'over'),\n",
       " ('so', 'stuff'),\n",
       " ('stuff', 'happened'),\n",
       " ('happened', 'sama'),\n",
       " ('sama', 'came'),\n",
       " ('came', 'home'),\n",
       " ('home', 'and'),\n",
       " ('and', 'she'),\n",
       " ('she', 'started'),\n",
       " ('started', 'to'),\n",
       " ('to', 'order'),\n",
       " ('order', 'me'),\n",
       " ('me', 'around'),\n",
       " ('around', 'then'),\n",
       " ('then', 'she'),\n",
       " ('she', 'got'),\n",
       " ('got', 'really'),\n",
       " ('really', 'mad'),\n",
       " ('mad', 'at'),\n",
       " ('at', 'me'),\n",
       " ('me', 'i'),\n",
       " ('i', 'stayed'),\n",
       " ('stayed', 'in'),\n",
       " ('in', 'my'),\n",
       " ('my', 'room'),\n",
       " ('room', 'most'),\n",
       " ('most', ''),\n",
       " ('', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'day'),\n",
       " ('day', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'going'),\n",
       " ('going', 'to'),\n",
       " ('to', \"nader's\"),\n",
       " (\"nader's\", 'house'),\n",
       " ('house', 'tomorrow'),\n",
       " ('tomorrow', 'and'),\n",
       " ('and', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'going'),\n",
       " ('going', 'to'),\n",
       " ('to', 'hang'),\n",
       " ('hang', 'out'),\n",
       " ('out', 'with'),\n",
       " ('with', 'him'),\n",
       " ('him', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'going'),\n",
       " ('going', 'to'),\n",
       " ('to', 'hang'),\n",
       " ('hang', 'out'),\n",
       " ('out', 'with'),\n",
       " ('with', 'robert'),\n",
       " ('robert', 'on'),\n",
       " ('on', 'wensday'),\n",
       " ('wensday', 'i'),\n",
       " ('i', 'worked'),\n",
       " ('worked', 'more'),\n",
       " ('more', 'on'),\n",
       " ('on', 'talis'),\n",
       " ('talis', 'lux'),\n",
       " ('lux', 'i'),\n",
       " ('i', 'also'),\n",
       " ('also', 'created'),\n",
       " ('created', 'a'),\n",
       " ('a', 'little'),\n",
       " ('little', 'roleplaying'),\n",
       " ('roleplaying', 'story'),\n",
       " ('story', 'for'),\n",
       " ('for', 'sarah'),\n",
       " ('sarah', 'and'),\n",
       " ('and', 'soha'),\n",
       " ('soha', 'when'),\n",
       " ('when', 'they'),\n",
       " ('they', 'come'),\n",
       " ('come', 'back'),\n",
       " ('back', 'i'),\n",
       " ('i', 'need'),\n",
       " ('need', 'to'),\n",
       " ('to', 'start'),\n",
       " ('start', 'working'),\n",
       " ('working', 'on'),\n",
       " ('on', 'desigining'),\n",
       " ('desigining', 'my'),\n",
       " ('my', 'website'),\n",
       " ('website', 'and'),\n",
       " ('and', 'my'),\n",
       " ('my', 'new'),\n",
       " ('new', 'resume'),\n",
       " ('resume', 'other'),\n",
       " ('other', 'than'),\n",
       " ('than', 'that'),\n",
       " ('that', 'i'),\n",
       " ('i', 'need'),\n",
       " ('need', 'a'),\n",
       " ('a', 'shower'),\n",
       " ('shower', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'having'),\n",
       " ('having', 'another'),\n",
       " ('another', 'phone'),\n",
       " ('phone', 'interview'),\n",
       " ('interview', 'with'),\n",
       " ('with', 'the'),\n",
       " ('the', 'cia'),\n",
       " ('cia', 'on'),\n",
       " ('on', 'jan'),\n",
       " ('jan', '7'),\n",
       " ('7', 'at'),\n",
       " ('at', '8:30'),\n",
       " ('8:30', 'am'),\n",
       " ('am', 'i'),\n",
       " ('i', 'have'),\n",
       " ('have', 'been'),\n",
       " ('been', 'trying'),\n",
       " ('trying', 'to'),\n",
       " ('to', 'work'),\n",
       " ('work', 'out'),\n",
       " ('out', 'my'),\n",
       " ('my', 'upper'),\n",
       " ('upper', 'body'),\n",
       " ('body', 'and'),\n",
       " ('and', 'now'),\n",
       " ('now', 'my'),\n",
       " ('my', 'arms'),\n",
       " ('arms', 'hurt'),\n",
       " ('yesterday', 'was'),\n",
       " ('was', \"sarah's\"),\n",
       " (\"sarah's\", 'birthday'),\n",
       " ('birthday', 'mom'),\n",
       " ('mom', 'soha'),\n",
       " ('soha', 'sarah'),\n",
       " ('sarah', 'and'),\n",
       " ('and', 'i'),\n",
       " ('i', 'went'),\n",
       " ('went', 'shopping'),\n",
       " ('shopping', 'and'),\n",
       " ('and', 'we'),\n",
       " ('we', 'got'),\n",
       " ('got', 'a'),\n",
       " ('a', 'lot'),\n",
       " ('lot', 'of'),\n",
       " ('of', 'stuff'),\n",
       " ('stuff', 'we'),\n",
       " ('we', 'got'),\n",
       " ('got', '$50'),\n",
       " ('$50', 'worth'),\n",
       " ('worth', 'of'),\n",
       " ('of', 'school'),\n",
       " ('school', 'supplies'),\n",
       " ('supplies', 'and'),\n",
       " ('and', 'then'),\n",
       " ('then', 'we'),\n",
       " ('we', 'went'),\n",
       " ('went', 'to'),\n",
       " ('to', 'target'),\n",
       " ('target', 'and'),\n",
       " ('and', 'spend'),\n",
       " ('spend', 'another'),\n",
       " ('another', '$80'),\n",
       " ('$80', 'dollars'),\n",
       " ('dollars', 'i'),\n",
       " ('i', 'got'),\n",
       " ('got', 'underwear'),\n",
       " ('underwear', 'then'),\n",
       " ('then', 'we'),\n",
       " ('we', 'went'),\n",
       " ('went', 'to'),\n",
       " ('to', 'pavilions'),\n",
       " ('pavilions', 'and'),\n",
       " ('and', 'pizza'),\n",
       " ('pizza', 'hut'),\n",
       " ('hut', 'sarah'),\n",
       " ('sarah', 'got'),\n",
       " ('got', 'a'),\n",
       " ('a', 'cake'),\n",
       " ('cake', 'i'),\n",
       " ('i', 'got'),\n",
       " ('got', 'a'),\n",
       " ('a', 'lot'),\n",
       " ('lot', 'of'),\n",
       " ('of', 'work'),\n",
       " ('work', 'for'),\n",
       " ('for', 'askoski'),\n",
       " ('askoski', 'and'),\n",
       " ('and', 'while'),\n",
       " ('while', 'i'),\n",
       " ('i', 'enjoy'),\n",
       " ('enjoy', 'the'),\n",
       " ('the', 'work'),\n",
       " ('work', 'i'),\n",
       " ('i', 'should'),\n",
       " ('should', 'start'),\n",
       " ('start', 'working'),\n",
       " ('working', 'on'),\n",
       " ('on', 'other'),\n",
       " ('other', 'things'),\n",
       " ('things', 'as'),\n",
       " ('as', 'well'),\n",
       " ('well', 'i'),\n",
       " ('i', 'go'),\n",
       " ('go', 'back'),\n",
       " ('back', 'very'),\n",
       " ('very', 'soon'),\n",
       " ('soon', 'and'),\n",
       " ('and', 'i'),\n",
       " ('i', 'need'),\n",
       " ('need', 'to'),\n",
       " ('to', 'study'),\n",
       " ('study', 'more'),\n",
       " ('more', 'probability'),\n",
       " ('probability', 'tomorrow'),\n",
       " ('tomorrow', 'i'),\n",
       " ('i', 'have'),\n",
       " ('have', 'to'),\n",
       " ('to', 'finalize'),\n",
       " ('finalize', 'my'),\n",
       " ('my', 'courses'),\n",
       " ('courses', 'for'),\n",
       " ('for', 'fall'),\n",
       " ('fall', 'nader'),\n",
       " ('nader', 'is'),\n",
       " ('is', 'coming'),\n",
       " ('coming', 'back'),\n",
       " ('back', 'on'),\n",
       " ('on', 'the'),\n",
       " ('the', '7th'),\n",
       " ('7th', 'i'),\n",
       " ('i', 'need'),\n",
       " ('need', 'to'),\n",
       " ('to', 'also'),\n",
       " ('also', 'start'),\n",
       " ('start', 'working'),\n",
       " ('working', 'out'),\n",
       " ('out', 'my'),\n",
       " ('my', 'upper'),\n",
       " ('upper', 'body'),\n",
       " ('body', 'i'),\n",
       " ('i', \"don't\"),\n",
       " (\"don't\", 'really'),\n",
       " ('really', 'get'),\n",
       " ('get', 'around'),\n",
       " ('around', 'to'),\n",
       " ('to', 'doing'),\n",
       " ('doing', 'that'),\n",
       " ('that', 'i'),\n",
       " ('i', 'also'),\n",
       " ('also', 'need'),\n",
       " ('need', 'to'),\n",
       " ('to', 'get'),\n",
       " ('get', 'my'),\n",
       " ('my', 'stuff'),\n",
       " ('stuff', 'together'),\n",
       " ('together', 'when'),\n",
       " ('when', 'i'),\n",
       " ('i', 'head'),\n",
       " ('head', 'back'),\n",
       " ('back', 'to'),\n",
       " ('to', 'berkeley'),\n",
       " ('berkeley', 'i'),\n",
       " ('i', 'already'),\n",
       " ('already', 'got'),\n",
       " ('got', 'my'),\n",
       " ('my', 'plane'),\n",
       " ('plane', 'ticket'),\n",
       " ('ticket', 'i'),\n",
       " ('i', 'tried'),\n",
       " ('tried', 'drawing'),\n",
       " ('drawing', 'a'),\n",
       " ('a', 'while'),\n",
       " ('while', 'ago'),\n",
       " ('ago', 'and'),\n",
       " ('and', 'i'),\n",
       " ('i', 'hope'),\n",
       " ('hope', 'to'),\n",
       " ('to', 'restart'),\n",
       " ('restart', 'it'),\n",
       " ('it', 'but'),\n",
       " ('but', 'that'),\n",
       " ('that', 'is'),\n",
       " ('is', 'pretty'),\n",
       " ('pretty', 'low'),\n",
       " ('low', 'priority'),\n",
       " ('priority', 'there'),\n",
       " ('there', 'is'),\n",
       " ('is', 'so'),\n",
       " ('so', 'much'),\n",
       " ('much', 'to'),\n",
       " ('to', 'do'),\n",
       " ('do', 'and'),\n",
       " ('and', 'i'),\n",
       " ('i', \"don't\"),\n",
       " (\"don't\", 'really'),\n",
       " ('really', 'want'),\n",
       " ('want', 'to'),\n",
       " ('to', 'do'),\n",
       " ('do', 'any'),\n",
       " ('any', 'of'),\n",
       " ('of', 'it'),\n",
       " ('so', 'i'),\n",
       " ('i', 'realized'),\n",
       " ('realized', 'that'),\n",
       " ('that', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'bad'),\n",
       " ('bad', 'with'),\n",
       " ('with', 'titles'),\n",
       " ('titles', 'and'),\n",
       " ('and', 'yeah'),\n",
       " ('yeah', 'that'),\n",
       " ('that', 'might'),\n",
       " ('might', 'become'),\n",
       " ('become', 'a'),\n",
       " ('a', 'problem'),\n",
       " ('problem', 'i'),\n",
       " ('i', 'wasted'),\n",
       " ('wasted', 'most'),\n",
       " ('most', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'day'),\n",
       " ('day', 'away'),\n",
       " ('away', 'watching'),\n",
       " ('watching', 'youtube'),\n",
       " ('youtube', 'and'),\n",
       " ('and', 'anime'),\n",
       " ('anime', 'although'),\n",
       " ('although', 'i'),\n",
       " ('i', 'did'),\n",
       " ('did', 'do'),\n",
       " ('do', 'some'),\n",
       " ('some', 'tutorials'),\n",
       " ('tutorials', 'in'),\n",
       " ('in', 'r'),\n",
       " ('r', 'and'),\n",
       " ('and', 'did'),\n",
       " ('did', 'one'),\n",
       " ('one', 'comp'),\n",
       " ('comp', 'sci'),\n",
       " ('sci', 'problem'),\n",
       " ('problem', 'i'),\n",
       " ('i', 'should'),\n",
       " ('should', 'get'),\n",
       " ('get', 'going'),\n",
       " ('going', 'on'),\n",
       " ('on', 'that'),\n",
       " ('that', 'i'),\n",
       " ('i', 'also'),\n",
       " ('also', 'got'),\n",
       " ('got', 'my'),\n",
       " ('my', 'transcript'),\n",
       " ('transcript', 'and'),\n",
       " ('and', 'sent'),\n",
       " ('sent', 'it'),\n",
       " ('it', 'out'),\n",
       " ('out', 'to'),\n",
       " ('to', 'some'),\n",
       " ('some', 'companies'),\n",
       " ('companies', \"soha's\"),\n",
       " (\"soha's\", 'friend'),\n",
       " ('friend', 'came'),\n",
       " ('came', 'over'),\n",
       " ('over', 'today'),\n",
       " ('today', 'yeah'),\n",
       " ('yeah', 'i'),\n",
       " ('i', 'got'),\n",
       " ('got', 'very'),\n",
       " ('very', 'little'),\n",
       " ('little', 'done'),\n",
       " ('done', 'mom'),\n",
       " ('mom', 'made'),\n",
       " ('made', 'an'),\n",
       " ('an', 'appointment'),\n",
       " ('appointment', 'with'),\n",
       " ('with', 'the'),\n",
       " ('the', 'dentist'),\n",
       " ('dentist', 'for'),\n",
       " ('for', 'me'),\n",
       " ('me', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'not'),\n",
       " ('not', 'looking'),\n",
       " ('looking', 'forward'),\n",
       " ('forward', 'to'),\n",
       " ('to', 'it'),\n",
       " ('it', 'i'),\n",
       " ('i', 'have'),\n",
       " ('have', 'been'),\n",
       " ('been', 'flossing'),\n",
       " ('flossing', 'and'),\n",
       " ('and', 'brushing'),\n",
       " ('brushing', 'though'),\n",
       " ('though', 'shoot'),\n",
       " ('shoot', 'i'),\n",
       " ('i', 'forgot'),\n",
       " ('forgot', 'to'),\n",
       " ('to', 'brush'),\n",
       " ('brush', 'my'),\n",
       " ('my', 'tongue'),\n",
       " ('tongue', 'so'),\n",
       " ('so', 'my'),\n",
       " ('my', 'plan'),\n",
       " ('plan', 'of'),\n",
       " ('of', 'stuff'),\n",
       " ('stuff', 'to'),\n",
       " ('to', 'do'),\n",
       " ('do', 'is'),\n",
       " ('is', 'learn'),\n",
       " ('learn', 'r'),\n",
       " ('r', 'do'),\n",
       " ('do', 'some'),\n",
       " ('some', 'kraggle'),\n",
       " ('kraggle', 'compeitions'),\n",
       " ('compeitions', 'finish'),\n",
       " ('finish', 'python'),\n",
       " ('python', 'and'),\n",
       " ('and', 'do'),\n",
       " ('do', 'some'),\n",
       " ('some', 'web'),\n",
       " ('web', 'dev'),\n",
       " ('dev', 'for'),\n",
       " ('for', 'my'),\n",
       " ('my', 'site'),\n",
       " ('site', 'this'),\n",
       " ('this', 'does'),\n",
       " ('does', 'not'),\n",
       " ('not', 'seem'),\n",
       " ('seem', 'like'),\n",
       " ('like', 'a'),\n",
       " ('a', 'lot'),\n",
       " ('lot', 'but'),\n",
       " ('but', 'me'),\n",
       " ('me', 'being'),\n",
       " ('being', 'lazy'),\n",
       " ('lazy', 'prevents'),\n",
       " ('prevents', 'me'),\n",
       " ('me', 'from'),\n",
       " ('from', 'doing'),\n",
       " ('doing', 'anything'),\n",
       " ('anything', 'then'),\n",
       " ('then', 'again'),\n",
       " ('again', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'a'),\n",
       " ('a', 'morning'),\n",
       " ('morning', 'person'),\n",
       " ('person', 'so'),\n",
       " ('so', 'maybe'),\n",
       " ('maybe', 'i'),\n",
       " ('i', 'just'),\n",
       " ('just', 'cannot'),\n",
       " ('cannot', 'do'),\n",
       " ('do', 'anything'),\n",
       " ('anything', 'at'),\n",
       " ('at', 'night'),\n",
       " ('night', 'i'),\n",
       " ('i', 'read'),\n",
       " ('read', 'on'),\n",
       " ('on', 'reddit'),\n",
       " ('reddit', 'that'),\n",
       " ('that', 'i'),\n",
       " ('i', 'should'),\n",
       " ('should', 'say'),\n",
       " ('say', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'demotivated'),\n",
       " ('demotivated', 'not'),\n",
       " ('not', 'lazy'),\n",
       " ('lazy', 'but'),\n",
       " ('but', 'to'),\n",
       " ('to', 'me'),\n",
       " ('me', 'they'),\n",
       " ('they', 'are'),\n",
       " ('are', 'the'),\n",
       " ('the', 'same'),\n",
       " ('same', 'thing'),\n",
       " ('thing', 'i'),\n",
       " ('i', 'have'),\n",
       " ('have', 'no'),\n",
       " ('no', 'want'),\n",
       " ('want', 'to'),\n",
       " ('to', 'work'),\n",
       " ('work', 'but'),\n",
       " ('but', 'i'),\n",
       " ('i', 'have'),\n",
       " ('have', 'to'),\n",
       " ('to', 'do'),\n",
       " ('do', 'it'),\n",
       " ('it', 'ugh'),\n",
       " ('ugh', 'kill'),\n",
       " ('kill', 'me'),\n",
       " ('me', 'is'),\n",
       " ('is', 'this'),\n",
       " ('this', 'really'),\n",
       " ('really', 'all'),\n",
       " ('all', 'i'),\n",
       " ('i', 'have'),\n",
       " ('have', 'to'),\n",
       " ('to', 'say'),\n",
       " ('say', 'man'),\n",
       " ('man', 'these'),\n",
       " ('these', 'are'),\n",
       " ('are', 'getting'),\n",
       " ('getting', 'short'),\n",
       " ('short', 'not'),\n",
       " ('not', 'much'),\n",
       " ('much', 'is'),\n",
       " ('is', 'going'),\n",
       " ('going', 'on'),\n",
       " ('on', 'my'),\n",
       " ('my', 'friends'),\n",
       " ('friends', 'did'),\n",
       " ('did', 'something'),\n",
       " ('something', 'today'),\n",
       " ('today', 'but'),\n",
       " ('but', 'i'),\n",
       " ('i', 'did'),\n",
       " ('did', 'not'),\n",
       " ('not', 'join'),\n",
       " ('join', 'well'),\n",
       " ('well', 'i'),\n",
       " ('i', 'guess'),\n",
       " ('guess', 'this'),\n",
       " ('this', 'ends'),\n",
       " ('ends', 'it'),\n",
       " ('so', 'my'),\n",
       " ('my', 'annoying'),\n",
       " ('annoying', 'sister'),\n",
       " ('sister', 'is'),\n",
       " ('is', 'right'),\n",
       " ('right', 'next'),\n",
       " ('next', 'to'),\n",
       " ('to', 'me'),\n",
       " ('me', 'just'),\n",
       " ('just', 'guess'),\n",
       " ('guess', 'which'),\n",
       " ('which', 'one'),\n",
       " ('one', 'it'),\n",
       " ('it', 'is'),\n",
       " ('is', 'my'),\n",
       " ('my', 'grades'),\n",
       " ('grades', 'have'),\n",
       " ('have', 'not'),\n",
       " ('not', 'been'),\n",
       " ('been', 'released'),\n",
       " ('released', 'yet'),\n",
       " ('yet', 'so'),\n",
       " ('so', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'kinda'),\n",
       " ('kinda', 'worried'),\n",
       " ('worried', 'i'),\n",
       " ('i', 'got'),\n",
       " ('got', 'one'),\n",
       " ('one', 'cavity'),\n",
       " ('cavity', 'and'),\n",
       " ('and', 'mom'),\n",
       " ('mom', 'is'),\n",
       " ('is', 'really'),\n",
       " ('really', 'upset'),\n",
       " ('upset', 'because'),\n",
       " ('because', 'i'),\n",
       " ('i', 'will'),\n",
       " ('will', 'need'),\n",
       " ('need', 'caps'),\n",
       " ('caps', 'on'),\n",
       " ('on', 'them'),\n",
       " ('them', 'i'),\n",
       " ('i', 'just'),\n",
       " ('just', \"don't\"),\n",
       " (\"don't\", 'get'),\n",
       " ('get', 'it'),\n",
       " ('it', 'because'),\n",
       " ('because', 'i'),\n",
       " ('i', 'brushed'),\n",
       " ('brushed', 'and'),\n",
       " ('and', 'flossed'),\n",
       " ('flossed', 'everyday'),\n",
       " ('everyday', 'i'),\n",
       " ('i', 'spent'),\n",
       " ('spent', 'yesterday'),\n",
       " ('yesterday', 'playing'),\n",
       " ('playing', 'dnd'),\n",
       " ('dnd', 'with'),\n",
       " ('with', 'my'),\n",
       " ('my', 'friends'),\n",
       " ('friends', 'which'),\n",
       " ('which', 'was'),\n",
       " ('was', 'pretty'),\n",
       " ('pretty', 'fun'),\n",
       " ('fun', 'problem'),\n",
       " ('problem', 'is'),\n",
       " ('is', 'that'),\n",
       " ('that', 'ali'),\n",
       " ('ali', 'keeps'),\n",
       " ('keeps', 'messing'),\n",
       " ('messing', 'up'),\n",
       " ('up', 'everything'),\n",
       " ('everything', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'going'),\n",
       " ('going', 'to'),\n",
       " ('to', 'have'),\n",
       " ('have', 'to'),\n",
       " ('to', 'kill'),\n",
       " ('kill', 'him'),\n",
       " ('him', 'artin'),\n",
       " ('artin', 'is'),\n",
       " ('is', 'playing'),\n",
       " ('playing', 'a'),\n",
       " ('a', 'plague'),\n",
       " ('plague', 'doctor'),\n",
       " ('doctor', 'which'),\n",
       " ('which', 'is'),\n",
       " ('is', 'kinda'),\n",
       " ('kinda', 'scary'),\n",
       " ('scary', 'but'),\n",
       " ('but', 'i'),\n",
       " ('i', 'believe'),\n",
       " ('believe', 'he'),\n",
       " ('he', 'is'),\n",
       " ('is', 'good'),\n",
       " ('good', 'i'),\n",
       " ('i', 'need'),\n",
       " ('need', 'to'),\n",
       " ('to', 'refocus'),\n",
       " ('refocus', 'on'),\n",
       " ('on', 'computer'),\n",
       " ('computer', 'science'),\n",
       " ('science', 'and'),\n",
       " ('and', 'studying'),\n",
       " ('studying', 'also'),\n",
       " ('also', 'running'),\n",
       " ('running', 'i'),\n",
       " ('i', 'need'),\n",
       " ('need', 'to'),\n",
       " ('to', 'start'),\n",
       " ('start', 'running'),\n",
       " ('running', 'or'),\n",
       " ('or', \"i'll\"),\n",
       " (\"i'll\", 'get'),\n",
       " ('get', 'fat'),\n",
       " ('fat', 'i'),\n",
       " ('i', 'made'),\n",
       " ('made', 'red'),\n",
       " ('red', 'beans'),\n",
       " ('beans', 'today'),\n",
       " ('today', 'and'),\n",
       " ('and', 'that'),\n",
       " ('that', 'was'),\n",
       " ('was', 'really'),\n",
       " ('really', 'good'),\n",
       " ('good', 'i'),\n",
       " ('i', 'have'),\n",
       " ('have', 'been'),\n",
       " ('been', 'sleeping'),\n",
       " ('sleeping', 'a'),\n",
       " ('a', 'lot'),\n",
       " ('lot', 'which'),\n",
       " ('which', 'is'),\n",
       " ('is', 'good'),\n",
       " ('good', 'in'),\n",
       " ('in', 'one'),\n",
       " ('one', 'way'),\n",
       " ('way', 'but'),\n",
       " ('but', 'then'),\n",
       " ('then', 'i'),\n",
       " ('i', 'lose'),\n",
       " ('lose', 'time'),\n",
       " ('time', 'to'),\n",
       " ('to', 'actually'),\n",
       " ('actually', 'work'),\n",
       " ('work', 'although'),\n",
       " ('although', 'when'),\n",
       " ('when', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'awake'),\n",
       " ('awake', 'i'),\n",
       " ('i', \"don't\"),\n",
       " (\"don't\", 'really'),\n",
       " ('really', 'work'),\n",
       " ('there', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'lot'),\n",
       " ('lot', 'going'),\n",
       " ('going', 'on'),\n",
       " ('on', 'but'),\n",
       " ('but', 'they'),\n",
       " ('they', 'all'),\n",
       " ('all', 'happen'),\n",
       " ('happen', 'later'),\n",
       " ('later', 'so'),\n",
       " ('so', 'right'),\n",
       " ('right', 'now'),\n",
       " ('now', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'pretty'),\n",
       " ('pretty', 'free'),\n",
       " ('free', 'i'),\n",
       " ('i', 'have'),\n",
       " ('have', 'been'),\n",
       " ('been', 'staring'),\n",
       " ('staring', 'at'),\n",
       " ('at', 'the'),\n",
       " ('the', 'computer'),\n",
       " ('computer', 'for'),\n",
       " ('for', 'too'),\n",
       " ('too', 'long'),\n",
       " ...]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, y_train, y_test = train_test_split(bigram_df['content'], bigram_df['goodMood'], \n",
    "                                                    test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame({word: data_train.str.count(re.escape(word)) for word in bigrams_train})\n",
    "X_test = pd.DataFrame({word: data_test.str.count(re.escape(word)) for word in bigrams_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6111111111111112, 0.6153846153846154, 0.47058823529411764)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_logistic_model = LogisticRegression(solver='lbfgs')\n",
    "bigram_logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = bigram_logistic_model.predict(X_test)\n",
    "acc_pre_rec(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_train = [list(nltk.trigrams(nltk.word_tokenize(s))) for s in trigram_df['content']]\n",
    "trigrams_train = [[a + ' ' + b + 'c' for a, b, c in l] for l in trigrams_train]\n",
    "_trigrams_train = np.unique(np.array(trigrams_train))\n",
    "trigrams_train = []\n",
    "for trigrams in _trigrams_train:\n",
    "            trigrams_train.extend(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, y_train, y_test = train_test_split(bigram_df['content'], bigram_df['goodMood'], \n",
    "                                                    test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame({word: data_train.str.count(re.escape(word)) for word in trigrams_train})\n",
    "X_test = pd.DataFrame({word: data_test.str.count(re.escape(word)) for word in trigrams_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5555555555555556, 1.0, 0.058823529411764705)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_logistic_model = LogisticRegression(solver='lbfgs')\n",
    "trigram_logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = trigram_logistic_model.predict(X_test)\n",
    "acc_pre_rec(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "w2v_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(w2v_df['content'])\n",
    "\n",
    "max_length = max([len(s.split()) for s in w2v_df['content']])\n",
    "vocab_size = len(tokenizer_obj.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, y_train, y_test = train_test_split(w2v_df['content'], w2v_df['goodMood'], \n",
    "                                                    test_size=0.2, random_state = 42)\n",
    "\n",
    "X_train_tokens = tokenizer_obj.texts_to_sequences(data_train)\n",
    "X_test_tokens = tokenizer_obj.texts_to_sequences(data_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 675, 100)          340200    \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 32)                12768     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 353,001\n",
      "Trainable params: 353,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "w2v_model = K.models.Sequential()\n",
    "w2v_model.add(K.layers.embeddings.Embedding(vocab_size, EMBEDDING_DIM, input_length=max_length))\n",
    "w2v_model.add(K.layers.GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "w2v_model.add(K.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "w2v_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "w2v_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 141 samples, validate on 36 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.6855 - accuracy: 0.5745 - val_loss: 0.6982 - val_accuracy: 0.5278\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.6836 - accuracy: 0.5745 - val_loss: 0.6962 - val_accuracy: 0.5278\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.6826 - accuracy: 0.5745 - val_loss: 0.6951 - val_accuracy: 0.5278\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.6810 - accuracy: 0.5745 - val_loss: 0.6948 - val_accuracy: 0.5278\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.6840 - accuracy: 0.5745 - val_loss: 0.6946 - val_accuracy: 0.5278\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.6792 - accuracy: 0.5745 - val_loss: 0.6945 - val_accuracy: 0.5278\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.6826 - accuracy: 0.5745 - val_loss: 0.6949 - val_accuracy: 0.5278\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.6831 - accuracy: 0.5745 - val_loss: 0.6950 - val_accuracy: 0.5278\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.6794 - accuracy: 0.5745 - val_loss: 0.6951 - val_accuracy: 0.5278\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.6866 - accuracy: 0.5745 - val_loss: 0.6943 - val_accuracy: 0.5278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f7e771bacf8>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.fit(X_train_pad, y_train, batch_size=32, epochs=10, validation_data=(X_test_pad, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "(\"module 'bert' has no attribute 'run_classifier'\", 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-310-d5e2124006c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                                    \u001b[0mtext_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_COLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                    \u001b[0mtext_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                                                    label = x[LABEL_COLUMN]), axis = 1)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6911\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6912\u001b[0m         )\n\u001b[0;32m-> 6913\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6915\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-310-d5e2124006c8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use the InputExample class from BERT's run_classifier code to create examples from the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                    \u001b[0mtext_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_COLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                    \u001b[0mtext_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                    label = x[LABEL_COLUMN]), axis = 1)\n",
      "\u001b[0;31mAttributeError\u001b[0m: (\"module 'bert' has no attribute 'run_classifier'\", 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-311-41038a386c96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         vocab_file=vocab_file, do_lower_case=do_lower_case)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tokenizer_from_hub_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-311-41038a386c96>\u001b[0m in \u001b[0;36mcreate_tokenizer_from_hub_module\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mbert_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBERT_MODEL_HUB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtokenization_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tokenization_info\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n\u001b[1;32m     11\u001b[0m                                             tokenization_info[\"do_lower_case\"]])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return bert.tokenization.FullTokenizer(\n",
    "        vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-312-9d57228bee50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.tokenize(train['sentence'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bert' has no attribute 'run_classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-313-4a7b57615e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMAX_SEQ_LENGTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert our train and test features to InputFeatures that BERT understands.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_examples_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_InputExamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_examples_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_InputExamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'bert' has no attribute 'run_classifier'"
     ]
    }
   ],
   "source": [
    "# We'll set sequences to be at most 128 tokens long.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "    bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "    bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "    output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        return (loss, predicted_labels, log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "\n",
    "            (loss, predicted_labels, log_probs) = create_model(\n",
    "                is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            train_op = bert.optimization.create_optimizer(\n",
    "                loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "          # Calculate evaluation metrics. \n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "                f1_score = tf.contrib.metrics.f1_score(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "                auc = tf.metrics.auc(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "                recall = tf.metrics.recall(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "                precision = tf.metrics.precision(\n",
    "                    label_ids,\n",
    "                    predicted_labels) \n",
    "                true_pos = tf.metrics.true_positives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "                true_neg = tf.metrics.true_negatives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)   \n",
    "                false_pos = tf.metrics.false_positives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)  \n",
    "                false_neg = tf.metrics.false_negatives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "                return {\n",
    "                    \"eval_accuracy\": accuracy,\n",
    "                    \"f1_score\": f1_score,\n",
    "                    \"auc\": auc,\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"true_positives\": true_pos,\n",
    "                    \"true_negatives\": true_neg,\n",
    "                    \"false_positives\": false_pos,\n",
    "                    \"false_negatives\": false_neg\n",
    "                }\n",
    "\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                    loss=loss,\n",
    "                    train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                    loss=loss,\n",
    "                    eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            (predicted_labels, log_probs) = create_model(\n",
    "                is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            predictions = {\n",
    "              'probabilities': log_probs,\n",
    "              'labels': predicted_labels\n",
    "              }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-317-28ee52e7b262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute # train and warmup steps from batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_train_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mNUM_TRAIN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnum_warmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_steps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mWARMUP_PROPORTION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_train_steps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-319-651f10edb60e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mnum_train_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   num_warmup_steps=num_warmup_steps)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_train_steps' is not defined"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bert' has no attribute 'run_classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-320-59efd55ea362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create an input function for training. drop_remainder = True for using TPUs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_input_fn = bert.run_classifier.input_fn_builder(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'bert' has no attribute 'run_classifier'"
     ]
    }
   ],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-321-6187edf75f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Beginning Training!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training took time \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'estimator' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-322-83c829f62ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m test_input_fn = run_classifier.input_fn_builder(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     drop_remainder=False)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-f6cdcd6190a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'estimator' is not defined"
     ]
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(in_sentences):\n",
    "    labels = [\"Negative\", \"Positive\"]\n",
    "    input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
    "    input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "    predictions = estimator.predict(predict_input_fn)\n",
    "    return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sentences = [\n",
    "  \"That movie was absolutely awful\",\n",
    "  \"The acting was a bit lacking\",\n",
    "  \"The film was creative and surprising\",\n",
    "  \"Absolutely fantastic!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sentence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentence'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-326-f991d50b24dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentence'"
     ]
    }
   ],
   "source": [
    "predictions = getPrediction(test['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'polarity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'polarity'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-327-9aa07e87a1e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'polarity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'polarity'"
     ]
    }
   ],
   "source": [
    "pol = np.array(test['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-328-b749446fff32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Positive'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Negative'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for p, i in zip(predictions, pol):\n",
    "  if (p[2] == 'Positive' and i == 1) or (p[2] == 'Negative' and i == 0):\n",
    "    t += 1\n",
    "\n",
    "1 - (t / len(pol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
